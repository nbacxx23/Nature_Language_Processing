{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29057 27184 1501 3374\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from numpy import array, ones, zeros, multiply\n",
    "import sys\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "import cPickle as pickle\n",
    "import math\n",
    "\n",
    "train_10 = pickle.load(open('/Users/xchen/Documents/AIC/TC4/projet/typos-data/train10.pkl', 'rb'))\n",
    "train_20 = pickle.load(open('/Users/xchen/Documents/AIC/TC4/projet/typos-data/train20.pkl', 'rb'))\n",
    "test_10 = pickle.load(open('/Users/xchen/Documents/AIC/TC4/projet/typos-data/test10.pkl', 'rb'))\n",
    "test_20 = pickle.load(open('/Users/xchen/Documents/AIC/TC4/projet/typos-data/test20.pkl', 'rb'))\n",
    "print len(train_10),len(train_20),len(test_10),len(test_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HMM2:\n",
    "        def __init__(self,state_list, observation_list, state2_list,\n",
    "                 transition_proba = None,\n",
    "                 transition2_proba = None,\n",
    "                 observation_proba = None,\n",
    "                 observation2_proba = None,\n",
    "                 initial_state_proba = None,smoothing_obs = 0.01,smoothing_trans2= 0.01):\n",
    "            \"\"\"Builds a new Hidden Markov Model\n",
    "            state_list is the list of state symbols [q_0...q_(N-1)]\n",
    "            observation_list is the list of observation symbols [v_0...v_(M-1)]\n",
    "            transition_proba is the transition probability matrix\n",
    "                [a_ij] a_ij = Pr(Y_(t+1)=q_i|Y_t=q_j)\n",
    "            observation_proba is the observation probablility matrix\n",
    "                [b_ki] b_ki = Pr(X_t=v_k|Y_t=q_i)\n",
    "            initial_state_proba is the initial state distribution\n",
    "                [pi_i] pi_i = Pr(Y_0=q_i)\"\"\"\n",
    "            print \"HMM creating with: \"\n",
    "            self.N = len(state_list) # The number of states\n",
    "            self.M = len(observation_list) # The number of words in the vocabulary\n",
    "            self.L = len(state2_list)\n",
    "            print str(self.N)+\" states\"\n",
    "            print str(self.L)+\" joint states\"\n",
    "            print str(self.M)+\" observations\"\n",
    "            self.omega_Y = state_list # Keep the vocabulary of tags\n",
    "            self.omega_X = observation_list # Keep the vocabulary of tags\n",
    "            self.omega_Y2 = state2_list\n",
    "            # Init. of the 3 distributions : observation, transition and initial states\n",
    "            if transition_proba is None:\n",
    "                self.transition_proba = zeros( (self.N, self.N), float) \n",
    "            else:\n",
    "                self.transition_proba=transition_proba\n",
    "            if transition2_proba is None:\n",
    "                self.transition2_proba = zeros((self.N,self.N,self.N),float)\n",
    "            else:\n",
    "                self.transition2_proba = transition2_proba\n",
    "            if observation_proba is None:\n",
    "                self.observation_proba = zeros( (self.M, self.N), float) \n",
    "            else:\n",
    "                self.observation_proba=observation_proba\n",
    "            if observation2_proba is None:\n",
    "                self.observation2_proba = zeros((self.N,self.N,self.N), float) \n",
    "            else:\n",
    "                self.observation2_proba=observation2_proba\n",
    "            if initial_state_proba is None:\n",
    "                self.initial_state_proba = zeros( (self.N,), float ) \n",
    "            else:\n",
    "                self.initial_state_proba=initial_state_proba\n",
    "            # Since everything will be stored in numpy arrays, it is more convenient and compact to \n",
    "            # handle words and tags as indices (integer) for a direct access. However, we also need \n",
    "            # to keep the mapping between strings (word or tag) and indices. \n",
    "            self.make_indexes()\n",
    "            self.smoothing_obs = smoothing_obs\n",
    "            self.smoothing_trans2 = smoothing_trans2\n",
    "\n",
    "        def make_indexes(self):\n",
    "            \"\"\"Creates the reverse table that maps states/observations names\n",
    "            to their index in the probabilities arrays\"\"\"\n",
    "            self.Y_index = {}\n",
    "            for i in range(self.N):\n",
    "                self.Y_index[self.omega_Y[i]] = i\n",
    "            self.X_index = {}\n",
    "            for i in range(self.M):\n",
    "                self.X_index[self.omega_X[i]] = i\n",
    "            self.Y2_index = {}\n",
    "            k=0\n",
    "            for i in self.omega_Y:\n",
    "                for j in self.omega_Y:\n",
    "                    self.Y2_index[(j,i)] =k\n",
    "                    k+=1\n",
    "                \n",
    "        def get_observationIndices( self, observations ):\n",
    "            \"\"\"return observation indices, i.e \n",
    "            return [self.O_index[o] for o in observations]\n",
    "            and deals with OOVs\n",
    "            \"\"\"\n",
    "            indices = zeros( len(observations), int )\n",
    "            k = 0\n",
    "            for o in observations:\n",
    "                if o in self.X_index:\n",
    "                    indices[k] = self.X_index[o]\n",
    "                else:\n",
    "                    indices[k] = UNKid\n",
    "                k += 1\n",
    "            return indices\n",
    "        \n",
    "        def data2indices(self, sent): \n",
    "            \"\"\"From one tagged sentence of the brown corpus: \n",
    "            - extract the words and tags \n",
    "            - returns two list of indices, one for each\n",
    "            -> (wordids, tagids)\n",
    "            \"\"\"\n",
    "            wordids = list()\n",
    "            tagids  = list()\n",
    "            for couple in sent:\n",
    "                wrd = couple[0]\n",
    "                tag = couple[1]\n",
    "                if wrd in self.X_index:\n",
    "                    wordids.append(self.X_index[wrd])\n",
    "                else:\n",
    "                    wordids.append(UNKid)\n",
    "                tagids.append(self.Y_index[tag])\n",
    "            return wordids,tagids\n",
    "        \n",
    "        def observation_estimation(self,pair_counts):\n",
    "            \"\"\" Build the observation distribution: \n",
    "                observation_proba is the observation probablility matrix\n",
    "                    [b_ki],  b_ki = Pr(X_t=v_k|Y_t=q_i)\"\"\"\n",
    "            # fill in with counts\n",
    "            for pair in pair_counts:\n",
    "                wrd=pair[0]\n",
    "                tag=pair[1]\n",
    "                cpt=pair_counts[pair]\n",
    "                k = 0 # for <unk>\n",
    "                if wrd in self.X_index: \n",
    "                    k=self.X_index[wrd]\n",
    "                i=self.Y_index[tag]\n",
    "                self.observation_proba[k,i]=cpt\n",
    "            # normalize\n",
    "            self.observation_proba=self.observation_proba+self.smoothing_obs\n",
    "            self.observation_proba=self.observation_proba/self.observation_proba.sum(axis=0).reshape(1,self.N)\n",
    "            \n",
    "        def observation2_estimation(self,pair2_counts):\n",
    "            \"\"\" Build the observation distribution: \n",
    "                observation_proba is the observation probablility matrix\n",
    "                    [b_ki],  b_ki = Pr(X_t=v_k|Y_t=q_i)\"\"\"\n",
    "            # fill in with counts\n",
    "            for pair in pair2_counts:\n",
    "                tag1=pair[0][0]\n",
    "                tag2=pair[0][1]\n",
    "                wrd=pair[1]\n",
    "                cpt=pair2_counts[pair]\n",
    "                k = 0 # for <unk>\n",
    "                if wrd in self.X_index: \n",
    "                    k=self.X_index[wrd]\n",
    "                i=self.Y_index[tag1]\n",
    "                j=self.Y_index[tag2]\n",
    "                self.observation2_proba[k,i,j]=cpt\n",
    "            # normalize\n",
    "            self.observation2_proba=self.observation2_proba+self.smoothing_obs\n",
    "            self.observation2_proba=self.observation2_proba/self.observation2_proba.sum(axis=0).reshape(1,self.N,self.N)\n",
    "        \n",
    "        def transition_estimation(self,trans_counts):\n",
    "            \"\"\" Build the transition distribution: \n",
    "                transition_proba is the transition matrix with : \n",
    "                [a_ij] a[i,j] = Pr(Y_(t+1)=q_i|Y_t=q_j)\n",
    "            \"\"\"\n",
    "            # fill with counts\n",
    "            for trans in trans_counts:\n",
    "                i=self.Y_index[trans[0]]\n",
    "                j=self.Y_index[trans[1]]\n",
    "                cpt = trans_counts[trans]\n",
    "                self.transition_proba[j,i] = cpt\n",
    "            # normalize\n",
    "            self.transition_proba = self.transition_proba/self.transition_proba.sum(axis =0).reshape(1,self.N)\n",
    "                \n",
    "        def transition2_estimation(self,trans2_counts):\n",
    "            for trans in trans2_counts:\n",
    "                i = self.Y_index[trans[0][0]]\n",
    "                j = self.Y_index[trans[0][1]]\n",
    "                k = self.Y_index[trans[1]]\n",
    "                cpt = trans2_counts[trans]\n",
    "                self.transition2_proba[k,i,j] = cpt\n",
    "            # normalize\n",
    "            self.transition2_proba=self.transition2_proba+self.smoothing_trans2\n",
    "            self.transition2_proba = self.transition2_proba/self.transition2_proba.sum(axis=0).reshape(1,self.N,self.N)\n",
    "    \n",
    "        def init_estimation(self,init_counts):\n",
    "            for init in init_counts:\n",
    "                index = self.Y_index[init]\n",
    "                self.initial_state_proba[index] = init_counts[init]\n",
    "            self.initial_state_proba = self.initial_state_proba/sum(self.initial_state_proba)\n",
    "            \n",
    "        def trans2_index(self):\n",
    "            self.Y2_state_index = {}\n",
    "            for i in self.Y2_index:\n",
    "                index = self.Y2_index[i]\n",
    "                i_1 = self.Y_index[i[1]]\n",
    "                self.Y2_state_index[index] = i_1\n",
    "        \n",
    "        def supervised_training(self, pair_counts, pair2_counts,trans_counts,trans2_counts,init_counts):\n",
    "            \"\"\" Train the HMM's parameters. This function wraps everything\"\"\"\n",
    "            self.trans2_index()\n",
    "            self.observation_estimation(pair_counts)\n",
    "            self.transition_estimation(trans_counts)\n",
    "            self.transition2_estimation(trans2_counts)\n",
    "            self.init_estimation(init_counts)\n",
    "            self.observation2_estimation(pair2_counts)\n",
    "            \n",
    "        def viterbi(self,obs): \n",
    "            B = self.observation_proba\n",
    "            B2 = self.observation2_proba\n",
    "            A = self.transition_proba\n",
    "            A2 = self.transition2_proba\n",
    "            T = len(obs)\n",
    "            N = self.N\n",
    "            \n",
    "            \n",
    "            delta = zeros((N,N),float)\n",
    "            psi = zeros((T-1,N,N),int)\n",
    "            delta_t = zeros((N,N),float)\n",
    "            \n",
    "            \n",
    "            if T<=2:\n",
    "                return self.viterbi1(obs)\n",
    "            else:\n",
    "                init = B[obs[0]]*self.initial_state_proba\n",
    "                for i in xrange(N):\n",
    "                    for j in xrange(N):\n",
    "                        delta[i,j]=init[i]*A[j,i]*B[obs[1]][j]\n",
    "                \n",
    "                for t in xrange(2,T):\n",
    "                    O_t = obs[t]\n",
    "                    for j in range(N):\n",
    "                        for k in range(N):\n",
    "                            temp = []\n",
    "                            for i in range(N):\n",
    "                                tmp = multiply(delta[i,j],A2[k,i,j])\n",
    "                                temp.append(tmp)\n",
    "                            idx = psi[t-1,j,k] = np.asarray(temp).argmax()\n",
    "                            delta_t[j,k] = temp[idx]*B2[O_t,j,k]\n",
    "                    delta,delta_t = delta_t,delta \n",
    "            \n",
    "                max_index = delta.argmax()\n",
    "                i_star = [max_index%N]\n",
    "                i_star.append(max_index/N)\n",
    "                temp = (i_star[1],i_star[0])\n",
    "            \n",
    "                for psi_t in psi[T-1:0:-1]:\n",
    "                    i_star.append(psi_t[temp[0]][temp[1]])\n",
    "                    temp = (psi_t[temp[0]][temp[1]],temp[0])\n",
    "                i_star.reverse()\n",
    "                return i_star\n",
    "            \n",
    "        def viterbi1(self,obs):\n",
    "            B = self.observation_proba\n",
    "            A = self.transition_proba\n",
    "            T = len(obs)\n",
    "            N = self.N\n",
    "            \n",
    "            delta = zeros(N,float)\n",
    "            tmp = zeros(N,float)\n",
    "            psi = zeros((T,N),int)\n",
    "            delta_t = zeros(N,float)\n",
    "            \n",
    "            delta = B[obs[0]]*self.initial_state_proba\n",
    "            for t in xrange(1,T):\n",
    "                O_t = obs[t]\n",
    "                for j in range(N):\n",
    "                    tmp = multiply(delta,A[j,:])\n",
    "                    idx = psi[t,j] = tmp.argmax()\n",
    "                    delta_t[j] = tmp[idx]*B[O_t,j]\n",
    "                delta,delta_t = delta_t,delta\n",
    "            i_star = [delta.argmax()]\n",
    "            temp = delta.argmax()\n",
    "            for psi_t in psi[T-1:0:-1]:\n",
    "                i_star.append(psi_t[temp])\n",
    "                temp = psi_t[temp]\n",
    "            i_star.reverse()\n",
    "            return i_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_counts2(data):\n",
    "    c_word = {}\n",
    "    c_tag = {}\n",
    "    c_tag2 = {}\n",
    "    c_pairs = {}\n",
    "    c_pairs2 = {}\n",
    "    c_transition = {}\n",
    "    c_transition2 = {}\n",
    "    c_init = {}\n",
    "    for d in data:\n",
    "        if not c_init.has_key(d[0][1]):\n",
    "            c_init[d[0][1]] = 1\n",
    "        else: c_init[d[0][1]] = c_init.get(d[0][1])+1\n",
    "        for i in xrange(len(d)):\n",
    "            if not c_word.has_key(d[i][0]):\n",
    "                c_word[d[i][0]] = 1\n",
    "            else: c_word[d[i][0]] = c_word.get(d[i][0])+1\n",
    "            if not c_tag.has_key(d[i][1]):\n",
    "                c_tag[d[i][1]] = 1\n",
    "            else: c_tag[d[i][1]] = c_tag.get(d[i][1])+1\n",
    "            if not c_pairs.has_key(d[i]):\n",
    "                c_pairs[d[i]] = 1\n",
    "            else: c_pairs[d[i]] = c_pairs.get(d[i])+1\n",
    "            if i <= len(d)-2:\n",
    "                if not c_pairs2.has_key(((d[i][1],d[i+1][1]),d[i+1][0])):\n",
    "                    c_pairs2[((d[i][1],d[i+1][1]),d[i+1][0])]=1\n",
    "                else: c_pairs2[((d[i][1],d[i+1][1]),d[i+1][0])] = c_pairs2.get(((d[i][1],d[i+1][1]),d[i+1][0]))+1\n",
    "            if i <= len(d)-2:\n",
    "                if not c_transition.has_key((d[i][1],d[i+1][1])):\n",
    "                    c_transition[(d[i][1],d[i+1][1])] = 1\n",
    "                else: c_transition[(d[i][1],d[i+1][1])] = c_transition.get((d[i][1],d[i+1][1]))+1\n",
    "            if i <= len(d)-2:\n",
    "                if not c_tag2.has_key((d[i][1],d[i+1][1])):\n",
    "                    c_tag2[(d[i][1],d[i+1][1])]=1\n",
    "                else: c_tag2[(d[i][1],d[i+1][1])] = c_tag2.get((d[i][1],d[i+1][1]))+1\n",
    "            if i <= len(d)-3:\n",
    "                if not c_transition2.has_key(((d[i][1],d[i+1][1]),d[i+2][1])):\n",
    "                    c_transition2[((d[i][1],d[i+1][1]),d[i+2][1])] = 1\n",
    "                else: c_transition2[((d[i][1],d[i+1][1]),d[i+2][1])] = c_transition2.get(((d[i][1],d[i+1][1]),d[i+2][1]))+1 \n",
    "    \n",
    "    return c_word,c_tag,c_tag2,c_pairs,c_pairs2,c_transition,c_transition2,c_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of observations: 26\n",
      "number of states: 26\n",
      "number of obs/state pairs: 127\n",
      "number of state-transition(first order): 403\n",
      "number of initial state: 25\n",
      "number of joint-states: 403\n",
      "number of obs2/(state1,state2): 1490\n",
      "number of state-transition(second order): 2489\n"
     ]
    }
   ],
   "source": [
    "c_words_train2,c_tags_train2,c_tags2_train2,c_pairs_train2,c_pairs2_train2,c_transition_train2,c_transition2_train2,c_init_train = make_counts2(train_10)\n",
    "print'number of observations:',len(c_words_train2)\n",
    "print 'number of states:',len(c_tags_train2)\n",
    "print 'number of obs/state pairs:',len(c_pairs_train2)\n",
    "print 'number of state-transition(first order):',len(c_transition_train2)\n",
    "print 'number of initial state:',len(c_init_train)\n",
    "print 'number of joint-states:',len(c_tags2_train2)\n",
    "print 'number of obs2/(state1,state2):',len(c_pairs2_train2)\n",
    "print 'number of state-transition(second order):',len(c_transition2_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM creating with: \n",
      "26 states\n",
      "403 joint states\n",
      "26 observations\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "[[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "1.0\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "hmm2_train = HMM2(state_list=c_tags_train2.keys(), observation_list=c_words_train2.keys(),\n",
    "                 state2_list= c_tags2_train2.keys(),\n",
    "                 transition_proba = None,\n",
    "                 observation_proba = None,\n",
    "                 initial_state_proba = None)\n",
    "hmm2_train.supervised_training(c_pairs_train2,c_pairs2_train2,c_transition_train2,c_transition2_train2,c_init_train)\n",
    "print hmm2_train.observation_proba.sum(axis =0)\n",
    "print hmm2_train.transition_proba.sum(axis =0)\n",
    "print hmm2_train.transition2_proba.sum(axis=0)\n",
    "print hmm2_train.observation2_proba.sum(axis=0)\n",
    "print sum(hmm2_train.initial_state_proba)\n",
    "print len(hmm2_train.observation_proba)\n",
    "print len(hmm2_train.transition_proba)\n",
    "print len(hmm2_train.transition2_proba)\n",
    "print len(hmm2_train.initial_state_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK : 6982.0 / 7320.0 -> 95.3825136612\n"
     ]
    }
   ],
   "source": [
    "tot_2 = 0.0\n",
    "correct_2 = 0.0\n",
    "confusion_2 = zeros([hmm2_train.N,hmm2_train.N])\n",
    "f = FloatProgress(min=0, max=len(test_10))\n",
    "display(f)\n",
    "for test in test_10:\n",
    "    f.value+=1\n",
    "    wordids_test,tagids_test = hmm2_train.data2indices(test)\n",
    "    tagids_pre = hmm2_train.viterbi(wordids_test)\n",
    "    for i in xrange(len(tagids_pre)):\n",
    "        hyp = tagids_pre[i]\n",
    "        ref = tagids_test[i]\n",
    "        if hyp == ref:\n",
    "            correct_2+=1\n",
    "        confusion_2[hyp][ref]+=1\n",
    "        tot_2+=1\n",
    "print \"OK : \"+str(correct_2)+\" / \"+str(tot_2)+ \" -> \"+ str(correct_2*100/tot_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
