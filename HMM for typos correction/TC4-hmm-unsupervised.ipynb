{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29057, 27184, 1501, 3374)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from numpy import array, ones, zeros, multiply\n",
    "import sys\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "import pickle\n",
    "\n",
    "train_10 = pickle.load(open( r\"/Users/feidong/Desktop/M2/TC4/typos-data/train10.pkl\", 'rb'))\n",
    "train_20 = pickle.load(open( r\"/Users/feidong/Desktop/M2/TC4/typos-data/train20.pkl\", 'rb'))\n",
    "test_10 = pickle.load(open( r\"/Users/feidong/Desktop/M2/TC4/typos-data/test10.pkl\" , 'rb'))\n",
    "test_20 = pickle.load(open( r\"/Users/feidong/Desktop/M2/TC4/typos-data/test20.pkl\", 'rb'))\n",
    "print (len(train_10),len(train_20),len(test_10),len(test_20))\n",
    "#print (test_10[2][1][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this class, we have reserved the most part of one order HMM, and add some functions of unsupervised training:\n",
    " ---def forward(self, obs)-----------------\n",
    " input: an unlabeled observation\n",
    " output: 1)an array alpha of forward probilities of an unlabeled observation; \n",
    "         2)the probility of the observation\n",
    " ---def backward(self,obs)-----------------\n",
    " input: an unlabeled observation\n",
    " output:  an array alpha of backward probilities of an unlabeled observation\n",
    " ---def make_count(self, sequences)--------\n",
    " input: list of unlabeled observations\n",
    " output: 1) C_init: an numpyarray which counts the probility of initial states;\n",
    "         2) C_trans: an numpyarray which counts the probility of transition between different states;\n",
    "         3) C_obs: an numpyarray which counts the probility of observation of different states.\n",
    " ---def update(self)-----------------------\n",
    " this function improves the inside parameters of the class:\n",
    " 1)initial_state_proba; 2)transition_proba  3)observation_proba\n",
    " ---def unsupervised training(self, sequences)--------------\n",
    " input: list of unlabeled observations\n",
    " this function run certain interations to get the estimated parameter of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class unsupervisedHMM:\n",
    "        def __init__(self, observation_list,\n",
    "                 transition_proba = None,\n",
    "                 observation_proba = None,\n",
    "                 initial_state_proba = None,smoothing_obs = 0.001):\n",
    "            \"\"\"Builds a new Hidden Markov Model\n",
    "            state_list is the list of state symbols [q_0...q_(N-1)]\n",
    "            observation_list is the list of observation symbols [v_0...v_(M-1)]\n",
    "            transition_proba is the transition probability matrix\n",
    "                [a_ij] a_ij = Pr(Y_(t+1)=q_i|Y_t=q_j)\n",
    "            observation_proba is the observation probablility matrix\n",
    "                [b_ki] b_ki = Pr(X_t=v_k|Y_t=q_i)\n",
    "            initial_state_proba is the initial state distribution\n",
    "                [pi_i] pi_i = Pr(Y_0=q_i)\"\"\"\n",
    "            print (\"HMM creating with: \")\n",
    "            #self.N = len(state_list) # The number of states\n",
    "            self.N = len(observation_list) #The number of states same as observed characters\n",
    "            self.M = len(observation_list) # The number of words in the vocabulary\n",
    "            print (str(self.N)+\" states\")\n",
    "            print (str(self.M)+\" observations\")\n",
    "            self.omega_Y = list(observation_list) # Keep the vocabulary of tags\n",
    "            self.omega_X = list(observation_list) # Keep the vocabulary of tags\n",
    "            # Init. of the 3 distributions : observation, transition and initial states\n",
    "            if transition_proba is None:\n",
    "                self.transition_proba = ones( (self.N, self.N), float)/self.N\n",
    "            else:\n",
    "                self.transition_proba=transition_proba\n",
    "            if observation_proba is None:\n",
    "                self.observation_proba = ones( (self.M, self.N), float)/self.M \n",
    "            else:\n",
    "                self.observation_proba=observation_proba\n",
    "            if initial_state_proba is None:\n",
    "                self.initial_state_proba = ones( (self.N,), float )/self.N \n",
    "            else:\n",
    "                self.initial_state_proba=initial_state_proba\n",
    "            # Since everything will be stored in numpy arrays, it is more convenient and compact to \n",
    "            # handle words and tags as indices (integer) for a direct access. However, we also need \n",
    "            # to keep the mapping between strings (word or tag) and indices. \n",
    "            self.make_indexes()\n",
    "            self.smoothing_obs = smoothing_obs\n",
    "\n",
    "        def make_indexes(self):\n",
    "            \"\"\"Creates the reverse table that maps states/observations names\n",
    "            to their index in the probabilities arrays\"\"\"\n",
    "            self.Y_index = {}\n",
    "            for i in range(self.N):\n",
    "                self.Y_index[self.omega_Y[i]] = i\n",
    "            self.X_index = {}\n",
    "            for i in range(self.M):\n",
    "                self.X_index[self.omega_X[i]] = i\n",
    "                \n",
    "        def get_observationIndices( self, observations ):\n",
    "            \"\"\"return observation indices, i.e \n",
    "            return [self.O_index[o] for o in observations]\n",
    "            and deals with OOVs\n",
    "            \"\"\"\n",
    "            indices = zeros( len(observations), int )\n",
    "            k = 0\n",
    "            for o in observations:\n",
    "                if o in self.X_index:\n",
    "                    indices[k] = self.X_index[o]\n",
    "                else:\n",
    "                    indices[k] = UNKid\n",
    "                k += 1\n",
    "            return indices\n",
    "        \n",
    "        def data2indices(self, sent): \n",
    "            \"\"\"From one tagged sentence of the brown corpus: \n",
    "            - extract the words and tags \n",
    "            - returns two list of indices, one for each\n",
    "            -> (wordids, tagids)\n",
    "            \"\"\"\n",
    "            wordids = list()\n",
    "            tagids  = list()\n",
    "            for couple in sent:\n",
    "                wrd = couple[0]\n",
    "                tag = couple[1]\n",
    "                if wrd in self.X_index:\n",
    "                    wordids.append(self.X_index[wrd])\n",
    "                tagids.append(self.Y_index[tag])\n",
    "            return wordids,tagids\n",
    "        \n",
    "        def observation_estimation(self,pair_counts):\n",
    "            \"\"\" Build the observation distribution: \n",
    "                observation_proba is the observation probablility matrix\n",
    "                    [b_ki],  b_ki = Pr(X_t=v_k|Y_t=q_i)\"\"\"\n",
    "            # fill in with counts\n",
    "            for pair in pair_counts:\n",
    "                wrd=pair[0]\n",
    "                tag=pair[1]\n",
    "                cpt=pair_counts[pair]\n",
    "                k = 0 # for <unk>\n",
    "                if wrd in self.X_index: \n",
    "                    k=self.X_index[wrd]\n",
    "                i=self.Y_index[tag]\n",
    "                self.observation_proba[k,i]=cpt\n",
    "            # normalize\n",
    "            self.observation_proba=self.observation_proba+self.smoothing_obs\n",
    "            self.observation_proba=self.observation_proba/self.observation_proba.sum(axis=0).reshape(1,self.N)\n",
    "        \n",
    "        def transition_estimation(self,trans_counts):\n",
    "            \"\"\" Build the transition distribution: \n",
    "                transition_proba is the transition matrix with : \n",
    "                [a_ij] a[i,j] = Pr(Y_(t+1)=q_i|Y_t=q_j)\n",
    "            \"\"\"\n",
    "            # fill with counts\n",
    "            for trans in trans_counts:\n",
    "                i=self.Y_index[trans[0]]\n",
    "                j=self.Y_index[trans[1]]\n",
    "                cpt = trans_counts[trans]\n",
    "                self.transition_proba[j,i] = cpt\n",
    "            # normalize\n",
    "            self.transition_proba = self.transition_proba/self.transition_proba.sum(axis = 0).reshape(1,self.N)\n",
    "                \n",
    "            \n",
    "        def init_estimation(self,init_counts):\n",
    "            for init in init_counts:\n",
    "                index = self.Y_index[init]\n",
    "                self.initial_state_proba[index] = init_counts[init]\n",
    "            self.initial_state_proba = self.initial_state_proba/sum(self.initial_state_proba)\n",
    "        \n",
    "        def supervised_training(self, pair_counts, trans_counts,init_counts):\n",
    "            \"\"\" Train the HMM's parameters. This function wraps everything\"\"\"\n",
    "            self.observation_estimation(pair_counts)\n",
    "            self.transition_estimation(trans_counts)\n",
    "            self.init_estimation(init_counts)\n",
    "            \n",
    "        def viterbi(self,obs):\n",
    "            B = self.observation_proba\n",
    "            A = self.transition_proba\n",
    "            T = len(obs)\n",
    "            N = self.N\n",
    "            \n",
    "            delta = zeros(N,float)\n",
    "            tmp = zeros(N,float)\n",
    "            psi = zeros((T,N),int)\n",
    "            delta_t = zeros(N,float)\n",
    "            \n",
    "            delta = B[obs[0]]*self.initial_state_proba\n",
    "            for t in range(1,T):\n",
    "                O_t = obs[t]\n",
    "                for j in range(N):\n",
    "                    tmp = multiply(delta,A[j,:])\n",
    "                    idx = psi[t,j] = tmp.argmax()\n",
    "                    delta_t[j] = tmp[idx]*B[O_t,j]\n",
    "                delta,delta_t = delta_t,delta\n",
    "            i_star = [delta.argmax()]\n",
    "            temp = delta.argmax()\n",
    "            for psi_t in psi[T-1:0:-1]:\n",
    "                i_star.append(psi_t[temp])\n",
    "                temp = psi_t[temp]\n",
    "            i_star.reverse()\n",
    "            return i_star\n",
    "        \n",
    "    \n",
    "        def forward(self, obs):\n",
    "            B = self.observation_proba\n",
    "            A = self.transition_proba\n",
    "            PI= self.initial_state_proba\n",
    "            T = len(obs)\n",
    "            N = self.N\n",
    "            alpha = [{}]\n",
    "\n",
    "            # Initialize base cases (t == 0)\n",
    "            for i in range(N):\n",
    "                alpha[0][i] = PI[i] * B[obs[0],i]\n",
    "            # Run Forward algorithm for t > 0\n",
    "            for t in range(1, T):\n",
    "                alpha.append({})     \n",
    "                for i in range(N):\n",
    "                    alpha[t][i] = sum((alpha[t-1][j] * A[i,j] * B[obs[t],i]) for j in range(N))\n",
    "            prob = sum((alpha[T - 1][i]) for i in range(N))\n",
    "            return alpha, prob\n",
    "    \n",
    "        def backward(self, obs):\n",
    "        \n",
    "            B = self.observation_proba\n",
    "            A = self.transition_proba\n",
    "            PI= self.initial_state_proba\n",
    "            T = len(obs)\n",
    "            N = self.N\n",
    "            \n",
    "            beta = [{} for t in range(T)]\n",
    "            # Initialize base cases (t == T)\n",
    "            for i in range(N):\n",
    "                beta[T-1][i] = 1 #A[i][\"Final\"] #PI[i] * B[i][obs[0]]\n",
    "            for t in reversed(range(T-1)):\n",
    "                for i in range(N):\n",
    "                    beta[t][i] = sum((beta[t+1][j] * A[j,i] * B[obs[t+1],j]) for j in range(N))\n",
    "            return beta\n",
    "        \n",
    "        \n",
    "        def make_counts(self, sequences):\n",
    "            B = self.observation_proba\n",
    "            A = self.transition_proba\n",
    "            PI= self.initial_state_proba\n",
    "            N = self.N\n",
    "            M=self.M\n",
    "            \n",
    "            f = FloatProgress(min=0, max=len(sequences))\n",
    "            display(f)\n",
    "            \n",
    "            C_trans=zeros( (N, N), float)\n",
    "            C_obs=zeros((M,N),float)\n",
    "            C_init=zeros(N,float)\n",
    "            \n",
    "            for obs in sequences:\n",
    "                f.value+=1\n",
    "                T=len(obs)\n",
    "                alpha,prob=self.forward(obs)\n",
    "                beta=self.backward(obs)\n",
    "                gamma=[[alpha[t][i]*beta[t][i] for i in range(N)] for t in range(T)]\n",
    "                C_init += gamma[0]/prob\n",
    "                MM=zeros((N,N),float)\n",
    "                for t in range(T):\n",
    "                    C_obs[obs[t]] += gamma[t]/prob\n",
    "                for t in range(T-1):\n",
    "                    for j in range(N):\n",
    "                        MM[:,j]=multiply(A[:,j],B[obs[t+1],:])\n",
    "                    P=[[alpha[t][j]*beta[t+1][i]*MM[i][j] for j in range(N)] for i in range(N)]\n",
    "                    C_trans+=P/prob\n",
    "            return C_trans,C_obs,C_init\n",
    "        \n",
    "        def update(self,C_trans,C_obs,C_init):\n",
    "            self.initial_state_proba=C_init/sum(C_init)\n",
    "            self.transition_proba=C_trans/C_trans.sum(axis = 0).reshape(1,self.N)\n",
    "            C_obs+=self.smoothing_obs\n",
    "            self.observation_proba=C_obs/C_obs.sum(axis = 0).reshape(1,self.N)\n",
    "            \n",
    "        def unsupervised_training(self,sequences):\n",
    "            #later add the converge condition\n",
    "            iteration      = 0\n",
    "            max_iterations = 20\n",
    "        \n",
    "            while iteration < max_iterations:\n",
    "                self.make_count(sequences)\n",
    "                self.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_counts(data):\n",
    "    c_letter_t = dict()\n",
    "    c_letter_c = dict()\n",
    "    c_pairs = dict()\n",
    "    c_transition = dict()\n",
    "    c_init = dict()\n",
    "    for d in data:   \n",
    "        if not d[0][1] in c_init:\n",
    "            c_init[d[0][1]]=1\n",
    "        else: c_init[d[0][1]] = c_init.get(d[0][1])+1\n",
    "        for i in range(len(d)):\n",
    "            if not d[i][0] in c_letter_t:\n",
    "                c_letter_t[d[i][0]] = 1\n",
    "            else: c_letter_t[d[i][0]] = c_letter_t.get(d[i][0])+1\n",
    "            if not d[i][1] in c_letter_c:\n",
    "                c_letter_c[d[i][1]] = 1\n",
    "            else: c_letter_c[d[i][1]] = c_letter_c.get(d[i][1])+1\n",
    "            if not d[i] in c_pairs:\n",
    "                c_pairs[d[i]] = 1\n",
    "            else: c_pairs[d[i]] = c_pairs.get(d[i])+1\n",
    "            if i <= len(d)-2:\n",
    "                if not (d[i][1],d[i+1][1]) in c_transition:\n",
    "                    c_transition[(d[i][1],d[i+1][1])] = 1\n",
    "                else: c_transition[(d[i][1],d[i+1][1])] = c_transition.get((d[i][1],d[i+1][1]))+1\n",
    "    \n",
    "    return c_letter_t,c_letter_c,c_pairs,c_transition,c_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 26, 127, 403, 25)\n"
     ]
    }
   ],
   "source": [
    "c_letter_t,c_letter_c,c_pairs,c_transition,c_init = make_counts(train_10)\n",
    "print (len(c_letter_t),len(c_letter_c),len(c_pairs),len(c_transition),len(c_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK : 6575.0 / 7320.0 -> 89.8224043716\n"
     ]
    }
   ],
   "source": [
    "tot = 0.0\n",
    "correct = 0.0\n",
    "#confusion = zeros([len(c_letter_c),len(c_letter_c)])\n",
    "f = FloatProgress(min=0, max=len(test_10))\n",
    "display(f)\n",
    "type_ids = list()\n",
    "correct_ids  = list()\n",
    "for origin in test_10:\n",
    "    f.value+=1\n",
    "    for i in origin:\n",
    "        type_ids.append(i[0])\n",
    "        correct_ids.append(i[1])\n",
    "    #type_ids,correct_ids = hmm_train.data2indices(origin)\n",
    "    #correct_ids_pre = hmm_train.viterbi(type_ids)\n",
    "for i in range(len(type_ids)):\n",
    "    f.value+=1\n",
    "    hyp = type_ids[i]\n",
    "    ref = correct_ids[i]\n",
    "    if hyp == ref:\n",
    "        correct+=1\n",
    "    #confusion[hyp][ref]+=1\n",
    "    tot+=1\n",
    "print (\"OK : \"+str(correct)+\" / \"+str(tot)+ \" -> \"+ str(correct*100/tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 26, 127, 403, 25)\n",
      "<type 'dict'>\n",
      "HMM creating with: \n",
      "26 states\n",
      "26 observations\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "1.0\n",
      "26\n",
      "26\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "c_words_train,c_tags_train,c_pairs_train,c_transition_train,c_init_train = make_counts(train_10)\n",
    "print (len(c_words_train),len(c_tags_train),len(c_pairs_train),len(c_transition_train),len(c_init_train))\n",
    "\n",
    "print(type(c_tags_train))\n",
    "\n",
    "hmm_train = unsupervisedHMM(observation_list=c_words_train,\n",
    "                 transition_proba = None,\n",
    "                 observation_proba = None,\n",
    "                 initial_state_proba = None)\n",
    "#hmm_train.supervised_training(c_pairs_train, c_transition_train,c_init_train)\n",
    "print (hmm_train.observation_proba.sum(axis =0))\n",
    "print (hmm_train.transition_proba.sum(axis =0))\n",
    "print (sum(hmm_train.initial_state_proba))\n",
    "print (len(hmm_train.observation_proba))\n",
    "print (len(hmm_train.transition_proba))\n",
    "print (len(hmm_train.initial_state_proba))\n",
    "\n",
    "#hmm_test.init_estimation(c_init_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sequences are takes the observations in train_10 as the training data for unsupervised training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sequences=[]\n",
    "tags=[]\n",
    "for train in train_10:\n",
    "    wordids,tagids= hmm_train.data2indices(train)\n",
    "    sequences.append(wordids)\n",
    "    tags.append(tagids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK : 6822.0 / 7320.0 -> 93.1967213115\n"
     ]
    }
   ],
   "source": [
    "tot_1 = 0.0\n",
    "correct_1 = 0.0\n",
    "confusion_1 = zeros([hmm_train.N,hmm_train.N])\n",
    "f = FloatProgress(min=0, max=len(test_10))\n",
    "display(f)\n",
    "for test in test_10:\n",
    "    f.value+=1\n",
    "    wordids_test,tagids_test = hmm_train.data2indices(test)\n",
    "    tagids_pre = hmm_train.viterbi(wordids_test)\n",
    "    for i in range(len(tagids_pre)):\n",
    "        hyp = tagids_pre[i]\n",
    "        ref = tagids_test[i]\n",
    "        if hyp == ref:\n",
    "            correct_1+=1\n",
    "        confusion_1[hyp][ref]+=1\n",
    "        tot_1+=1\n",
    "print (\"OK : \"+str(correct_1)+\" / \"+str(tot_1)+ \" -> \"+ str(correct_1*100/tot_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
