{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29057 27184 1501 3374\n",
      "[('i', 'i'), ('s', 's')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy\n",
    "from numpy import array, ones, zeros, multiply\n",
    "import sys\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "import cPickle as pickle  \n",
    "\n",
    "train_10 = pickle.load(open('/Users/xchen/Documents/AIC/TC4/projet/typos-data/train10.pkl', 'rb'))\n",
    "train_20 = pickle.load(open('/Users/xchen/Documents/AIC/TC4/projet/typos-data/train20.pkl', 'rb'))\n",
    "test_10 = pickle.load(open('/Users/xchen/Documents/AIC/TC4/projet/typos-data/test10.pkl', 'rb'))\n",
    "test_20 = pickle.load(open('/Users/xchen/Documents/AIC/TC4/projet/typos-data/test20.pkl', 'rb'))\n",
    "print len(train_10),len(train_20),len(test_10),len(test_20)\n",
    "print test_10[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HMM:\n",
    "        def __init__(self,state_list, observation_list,\n",
    "                 transition_proba = None,\n",
    "                 observation_proba = None,\n",
    "                 initial_state_proba = None,smoothing_obs = 0.01):\n",
    "            \"\"\"Builds a new Hidden Markov Model\n",
    "            state_list is the list of state symbols [q_0...q_(N-1)]\n",
    "            observation_list is the list of observation symbols [v_0...v_(M-1)]\n",
    "            transition_proba is the transition probability matrix\n",
    "                [a_ij] a_ij = Pr(Y_(t+1)=q_i|Y_t=q_j)\n",
    "            observation_proba is the observation probablility matrix\n",
    "                [b_ki] b_ki = Pr(X_t=v_k|Y_t=q_i)\n",
    "            initial_state_proba is the initial state distribution\n",
    "                [pi_i] pi_i = Pr(Y_0=q_i)\"\"\"\n",
    "            print \"HMM creating with: \"\n",
    "            self.N = len(state_list) # The number of states\n",
    "            self.M = len(observation_list) # The number of words in the vocabulary\n",
    "            print str(self.N)+\" states\"\n",
    "            print str(self.M)+\" observations\"\n",
    "            self.omega_Y = state_list # Keep the vocabulary of tags\n",
    "            self.omega_X = observation_list # Keep the vocabulary of tags\n",
    "            # Init. of the 3 distributions : observation, transition and initial states\n",
    "            if transition_proba is None:\n",
    "                self.transition_proba = zeros( (self.N, self.N), float) \n",
    "            else:\n",
    "                self.transition_proba=transition_proba\n",
    "            if observation_proba is None:\n",
    "                self.observation_proba = zeros( (self.M, self.N), float) \n",
    "            else:\n",
    "                self.observation_proba=observation_proba\n",
    "            if initial_state_proba is None:\n",
    "                self.initial_state_proba = zeros( (self.N,), float ) \n",
    "            else:\n",
    "                self.initial_state_proba=initial_state_proba\n",
    "            # Since everything will be stored in numpy arrays, it is more convenient and compact to \n",
    "            # handle words and tags as indices (integer) for a direct access. However, we also need \n",
    "            # to keep the mapping between strings (word or tag) and indices. \n",
    "            self.make_indexes()\n",
    "            self.smoothing_obs = smoothing_obs\n",
    "\n",
    "        def make_indexes(self):\n",
    "            \"\"\"Creates the reverse table that maps states/observations names\n",
    "            to their index in the probabilities arrays\"\"\"\n",
    "            self.Y_index = {}\n",
    "            for i in range(self.N):\n",
    "                self.Y_index[self.omega_Y[i]] = i\n",
    "            self.X_index = {}\n",
    "            for i in range(self.M):\n",
    "                self.X_index[self.omega_X[i]] = i\n",
    "                \n",
    "        def get_observationIndices( self, observations ):\n",
    "            \"\"\"return observation indices, i.e \n",
    "            return [self.O_index[o] for o in observations]\n",
    "            and deals with OOVs\n",
    "            \"\"\"\n",
    "            indices = zeros( len(observations), int )\n",
    "            k = 0\n",
    "            for o in observations:\n",
    "                if o in self.X_index:\n",
    "                    indices[k] = self.X_index[o]\n",
    "                else:\n",
    "                    indices[k] = UNKid\n",
    "                k += 1\n",
    "            return indices\n",
    "        \n",
    "        def data2indices(self, sent): \n",
    "            \"\"\"From one tagged sentence of the brown corpus: \n",
    "            - extract the words and tags \n",
    "            - returns two list of indices, one for each\n",
    "            -> (wordids, tagids)\n",
    "            \"\"\"\n",
    "            wordids = list()\n",
    "            tagids  = list()\n",
    "            for couple in sent:\n",
    "                wrd = couple[0]\n",
    "                tag = couple[1]\n",
    "                if wrd in self.X_index:\n",
    "                    wordids.append(self.X_index[wrd])\n",
    "                tagids.append(self.Y_index[tag])\n",
    "            return wordids,tagids\n",
    "        \n",
    "        def observation_estimation(self,pair_counts):\n",
    "            \"\"\" Build the observation distribution: \n",
    "                observation_proba is the observation probablility matrix\n",
    "                    [b_ki],  b_ki = Pr(X_t=v_k|Y_t=q_i)\"\"\"\n",
    "            # fill in with counts\n",
    "            for pair in pair_counts:\n",
    "                wrd=pair[0]\n",
    "                tag=pair[1]\n",
    "                cpt=pair_counts[pair]\n",
    "                k = 0 # for <unk>\n",
    "                if wrd in self.X_index: \n",
    "                    k=self.X_index[wrd]\n",
    "                i=self.Y_index[tag]\n",
    "                self.observation_proba[k,i]=cpt\n",
    "            # normalize\n",
    "            self.observation_proba=self.observation_proba+self.smoothing_obs\n",
    "            self.observation_proba=self.observation_proba/self.observation_proba.sum(axis=0).reshape(1,self.N)\n",
    "        \n",
    "        def transition_estimation(self,trans_counts):\n",
    "            \"\"\" Build the transition distribution: \n",
    "                transition_proba is the transition matrix with : \n",
    "                [a_ij] a[i,j] = Pr(Y_(t+1)=q_i|Y_t=q_j)\n",
    "            \"\"\"\n",
    "            # fill with counts\n",
    "            for trans in trans_counts:\n",
    "                i=self.Y_index[trans[0]]\n",
    "                j=self.Y_index[trans[1]]\n",
    "                cpt = trans_counts[trans]\n",
    "                self.transition_proba[j,i] = cpt\n",
    "            # normalize\n",
    "            self.transition_proba = self.transition_proba/self.transition_proba.sum(axis = 0).reshape(1,self.N)\n",
    "                \n",
    "            \n",
    "        def init_estimation(self,init_counts):\n",
    "            for init in init_counts:\n",
    "                index = self.Y_index[init]\n",
    "                self.initial_state_proba[index] = init_counts[init]\n",
    "            self.initial_state_proba = self.initial_state_proba/sum(self.initial_state_proba)\n",
    "        \n",
    "        def supervised_training(self, pair_counts, trans_counts,init_counts):\n",
    "            \"\"\" Train the HMM's parameters. This function wraps everything\"\"\"\n",
    "            self.observation_estimation(pair_counts)\n",
    "            self.transition_estimation(trans_counts)\n",
    "            self.init_estimation(init_counts)\n",
    "            \n",
    "        def viterbi(self,obs):\n",
    "            B = self.observation_proba\n",
    "            A = self.transition_proba\n",
    "            T = len(obs)\n",
    "            N = self.N\n",
    "            \n",
    "            delta = zeros(N,float)\n",
    "            tmp = zeros(N,float)\n",
    "            psi = zeros((T,N),int)\n",
    "            delta_t = zeros(N,float)\n",
    "            \n",
    "            delta = B[obs[0]]*self.initial_state_proba\n",
    "            for t in xrange(1,T):\n",
    "                O_t = obs[t]\n",
    "                for j in range(N):\n",
    "                    tmp = multiply(delta,A[j,:])\n",
    "                    idx = psi[t,j] = tmp.argmax()\n",
    "                    delta_t[j] = tmp[idx]*B[O_t,j]\n",
    "                delta,delta_t = delta_t,delta\n",
    "            i_star = [delta.argmax()]\n",
    "            temp = delta.argmax()\n",
    "            for psi_t in psi[T-1:0:-1]:\n",
    "                i_star.append(psi_t[temp])\n",
    "                temp = psi_t[temp]\n",
    "            i_star.reverse()\n",
    "            return i_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_counts(data):\n",
    "    c_letter_t = {}\n",
    "    c_letter_c = {}\n",
    "    c_pairs = {}\n",
    "    c_transition = {}\n",
    "    c_init = {}\n",
    "    for d in data:   \n",
    "        if not c_init.has_key(d[0][1]):\n",
    "            c_init[d[0][1]]=1\n",
    "        else: c_init[d[0][1]] = c_init.get(d[0][1])+1\n",
    "        for i in xrange(len(d)):\n",
    "            if not c_letter_t.has_key(d[i][0]):\n",
    "                c_letter_t[d[i][0]] = 1\n",
    "            else: c_letter_t[d[i][0]] = c_letter_t.get(d[i][0])+1\n",
    "            if not c_letter_c.has_key(d[i][1]):\n",
    "                c_letter_c[d[i][1]] = 1\n",
    "            else: c_letter_c[d[i][1]] = c_letter_c.get(d[i][1])+1\n",
    "            if not c_pairs.has_key(d[i]):\n",
    "                c_pairs[d[i]] = 1\n",
    "            else: c_pairs[d[i]] = c_pairs.get(d[i])+1\n",
    "            if i <= len(d)-2:\n",
    "                if not c_transition.has_key((d[i][1],d[i+1][1])):\n",
    "                    c_transition[(d[i][1],d[i+1][1])] = 1\n",
    "                else: c_transition[(d[i][1],d[i+1][1])] = c_transition.get((d[i][1],d[i+1][1]))+1\n",
    "    \n",
    "    return c_letter_t,c_letter_c,c_pairs,c_transition,c_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of observations: 26\n",
      "number of states: 26\n",
      "number of obs/state pairs: 127\n",
      "number of transitions: 403\n",
      "number of initial state: 25\n"
     ]
    }
   ],
   "source": [
    "c_letter_t,c_letter_c,c_pairs,c_transition,c_init = make_counts(train_10)\n",
    "print 'number of observations:',len(c_letter_t)\n",
    "print 'number of states:',len(c_letter_c)\n",
    "print 'number of obs/state pairs:',len(c_pairs)\n",
    "print 'number of transitions:',len(c_transition) \n",
    "print 'number of initial state:',len(c_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK : 6575.0 / 7320.0 -> 89.8224043716\n"
     ]
    }
   ],
   "source": [
    "tot = 0.0\n",
    "correct = 0.0\n",
    "#confusion = zeros([len(c_letter_c),len(c_letter_c)])\n",
    "f = FloatProgress(min=0, max=len(test_10))\n",
    "display(f)\n",
    "type_ids = list()\n",
    "correct_ids  = list()\n",
    "for origin in test_10:\n",
    "    f.value+=1\n",
    "    for i in origin:\n",
    "        type_ids.append(i[0])\n",
    "        correct_ids.append(i[1])\n",
    "    #type_ids,correct_ids = hmm_train.data2indices(origin)\n",
    "    #correct_ids_pre = hmm_train.viterbi(type_ids)\n",
    "for i in xrange(len(type_ids)):\n",
    "    f.value+=1\n",
    "    hyp = type_ids[i]\n",
    "    ref = correct_ids[i]\n",
    "    if hyp == ref:\n",
    "        correct+=1\n",
    "    #confusion[hyp][ref]+=1\n",
    "    tot+=1\n",
    "print \"OK : \"+str(correct)+\" / \"+str(tot)+ \" -> \"+ str(correct*100/tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 127 403 25\n",
      "HMM creating with: \n",
      "26 states\n",
      "26 observations\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "1.0\n",
      "26\n",
      "26\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "c_words_train,c_tags_train,c_pairs_train,c_transition_train,c_init_train = make_counts(train_10)\n",
    "print len(c_words_train),len(c_tags_train),len(c_pairs_train),len(c_transition_train),len(c_init_train)\n",
    "\n",
    "hmm_train = HMM(state_list=c_tags_train.keys(), observation_list=c_words_train.keys(),\n",
    "                 transition_proba = None,\n",
    "                 observation_proba = None,\n",
    "                 initial_state_proba = None)\n",
    "hmm_train.supervised_training(c_pairs_train, c_transition_train,c_init_train)\n",
    "print hmm_train.observation_proba.sum(axis =0)\n",
    "print hmm_train.transition_proba.sum(axis =0)\n",
    "print sum(hmm_train.initial_state_proba)\n",
    "print len(hmm_train.observation_proba)\n",
    "print len(hmm_train.transition_proba)\n",
    "print len(hmm_train.initial_state_proba)\n",
    "\n",
    "#hmm_test.init_estimation(c_init_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.06445951e-01   4.16422893e-02   4.91791995e-02   3.02853013e-02\n",
      "   2.93560932e-02   1.68634064e-02   3.56196441e-02   8.09443508e-02\n",
      "   3.60670406e-02   2.71879409e-03   1.85841622e-03   4.03000998e-02\n",
      "   2.32302027e-02   7.88450287e-02   2.60522421e-02   1.17011391e-03\n",
      "   5.28272017e-02   7.47496300e-02   2.60866573e-02   9.91155315e-03\n",
      "   1.74071652e-01   5.44447121e-02   4.68045566e-03   2.54671852e-03\n",
      "   1.03245345e-04   0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print hmm_train.initial_state_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK : 6822.0 / 7320.0 -> 93.1967213115\n"
     ]
    }
   ],
   "source": [
    "tot_1 = 0.0\n",
    "correct_1 = 0.0\n",
    "confusion_1 = zeros([hmm_train.N,hmm_train.N])\n",
    "f = FloatProgress(min=0, max=len(test_10))\n",
    "display(f)\n",
    "for test in test_10:\n",
    "    f.value+=1\n",
    "    wordids_test,tagids_test = hmm_train.data2indices(test)\n",
    "    tagids_pre = hmm_train.viterbi(wordids_test)\n",
    "    for i in xrange(len(tagids_pre)):\n",
    "        hyp = tagids_pre[i]\n",
    "        ref = tagids_test[i]\n",
    "        if hyp == ref:\n",
    "            correct_1+=1\n",
    "        confusion_1[hyp][ref]+=1\n",
    "        tot_1+=1\n",
    "print \"OK : \"+str(correct_1)+\" / \"+str(tot_1)+ \" -> \"+ str(correct_1*100/tot_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
